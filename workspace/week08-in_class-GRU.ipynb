{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d834c5bb-ad31-4f66-8c20-4580aff623e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# -----------------------------\n",
    "# Character-level next-char model with a GRU (complete, runnable)\n",
    "# -----------------------------\n",
    "text = (\n",
    "    \"hello Georgetown from scratch!\\n\"\n",
    "    \"this is a slightly longer training string so the model has more to learn.\\n\"\n",
    "    \"gru models usually learn faster than vanilla rnn.\\n\"\n",
    ")\n",
    "\n",
    "# Build vocabulary\n",
    "chars = sorted(set(text))\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "V = len(chars)\n",
    "\n",
    "encoded = np.array([stoi[ch] for ch in text], dtype=np.int32)\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset: (input_seq -> target_seq), where target is the next char at each step\n",
    "# -----------------------------\n",
    "seq_len = 40\n",
    "batch_size = 32\n",
    "\n",
    "def make_dataset(encoded, seq_len, batch_size):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(encoded) - seq_len):\n",
    "        xs.append(encoded[i : i + seq_len])\n",
    "        ys.append(encoded[i + 1 : i + seq_len + 1])\n",
    "    xs = np.stack(xs).astype(np.int32)  # (N, T)\n",
    "    ys = np.stack(ys).astype(np.int32)  # (N, T)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((xs, ys))\n",
    "    ds = ds.shuffle(min(2048, len(xs))).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "ds = make_dataset(encoded, seq_len, batch_size)\n",
    "\n",
    "# -----------------------------\n",
    "# Model: Embedding -> GRU -> Dense(vocab)\n",
    "# -----------------------------\n",
    "embed_dim = 64\n",
    "hidden_size = 256\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(seq_len,), dtype=\"int32\"),\n",
    "    layers.Embedding(input_dim=V, output_dim=embed_dim),\n",
    "    layers.GRU(hidden_size, return_sequences=True),\n",
    "    layers.Dense(V)  # logits per time step\n",
    "])\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"sparse_categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "# Train\n",
    "model.fit(ds, epochs=30, verbose=2)\n",
    "\n",
    "# -----------------------------\n",
    "# Sampling / generation\n",
    "# -----------------------------\n",
    "@tf.function\n",
    "def last_step_logits(model, x):\n",
    "    # x: (1, T) int32\n",
    "    logits = model(x, training=False)      # (1, T, V)\n",
    "    return logits[:, -1, :]                # (1, V)\n",
    "\n",
    "def sample(model, start_text=\"h\", n=200, temperature=0.9):\n",
    "    # Seed context: if start_text shorter than seq_len, pad with its first char\n",
    "    start_ids = [stoi[c] for c in start_text if c in stoi]\n",
    "    if len(start_ids) == 0:\n",
    "        start_ids = [0]\n",
    "\n",
    "    context = (start_ids + [start_ids[0]] * seq_len)[-seq_len:]  # length = seq_len\n",
    "    out_ids = list(start_ids)\n",
    "\n",
    "    for _ in range(n - len(out_ids)):\n",
    "        x = tf.constant([context], dtype=tf.int32)\n",
    "        logits = last_step_logits(model, x) / float(temperature)\n",
    "        probs = tf.nn.softmax(logits, axis=-1).numpy().ravel()\n",
    "        next_id = int(np.random.choice(V, p=probs))\n",
    "\n",
    "        out_ids.append(next_id)\n",
    "        context = context[1:] + [next_id]\n",
    "\n",
    "    return \"\".join(itos[i] for i in out_ids)\n",
    "\n",
    "print(\"\\n--- samples ---\")\n",
    "for temp in (0.6, 0.9, 1.2):\n",
    "    print(f\"\\nTemperature={temp}\")\n",
    "    print(sample(model, start_text=\"hello \", n=300, temperature=temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3fad55-47d7-4db0-95fd-2b9778d7406c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
