{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5170f8d6-900a-4ce9-84e0-05ed38d7ed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) Load the CSV\n",
    "df = pd.read_csv(\"data/auto-mpg.csv\")\n",
    "\n",
    "# 2) Look for columns that are \"text\" but mostly contain numbers\n",
    "for col in df.columns:\n",
    "    # If pandas thinks it's text (object), it *might* really be numeric\n",
    "    if df[col].dtype == \"object\":\n",
    "        # Try converting to numbers (anything that can't convert becomes NaN)\n",
    "        as_num = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "        # Count how many non-empty values exist, and how many become numbers\n",
    "        non_missing = df[col].notna().sum()\n",
    "        numeric_count = as_num.notna().sum()\n",
    "\n",
    "        # If most of the non-missing values convert to numbers, flag it\n",
    "        if non_missing > 0 and numeric_count / non_missing >= 0.9:\n",
    "            print(f\"Column '{col}' might be numeric but loaded as text.\")\n",
    "            print(\"  examples:\", df[col].dropna().head(5).tolist())\n",
    "            print()\n",
    "    else:\n",
    "        print(f\"Column '{col}' appears to be numeric.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cffb72-67db-45a6-b314-bfb029cf2ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5528b8-9cbc-48d0-bef3-d109df1d2ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training (70%) and test (30%) sets\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.30,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# Print dimensions of each set\n",
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a3a850-14a5-4d3f-bf5d-509276a61d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- TRAINING SET ----\n",
    "print(\"Training set missing values (before):\")\n",
    "print(train_df.isna().sum())\n",
    "\n",
    "# Fill missing values with column medians\n",
    "train_df = train_df.fillna(train_df.median(numeric_only=True))\n",
    "\n",
    "print(\"\\nTraining set missing values (after):\")\n",
    "print(train_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d98031-2ba8-452a-839e-f1d4fd6e463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- TEST SET ----\n",
    "print(\"\\nTest set missing values (before):\")\n",
    "print(test_df.isna().sum())\n",
    "\n",
    "# Fill missing values with column medians\n",
    "test_df = test_df.fillna(test_df.median(numeric_only=True))\n",
    "\n",
    "print(\"\\nTest set missing values (after):\")\n",
    "print(test_df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64237208-431f-492a-8733-a97081d70f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb7d941-ff00-45a1-a2cd-5639b8228db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "# -------------------------------\n",
    "# Normalize continuous features\n",
    "# -------------------------------\n",
    "\n",
    "# Choose continuous columns (example ones)\n",
    "continuous_cols = [\"horsepower\", \"weight\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data, transform both\n",
    "train_df[continuous_cols] = scaler.fit_transform(train_df[continuous_cols])\n",
    "test_df[continuous_cols] = scaler.transform(test_df[continuous_cols])\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6a51fe-d383-49f7-940f-24a1ff3f5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# Add polynomial features (squared)\n",
    "# --------------------------------\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Apply only to horsepower for simplicity\n",
    "## learn the poly model from training set\n",
    "horsepower_train_poly = poly.fit_transform(train_df[[\"horsepower\"]])\n",
    "\n",
    "## aply the same transform to the test set\n",
    "horsepower_test_poly  = poly.transform(test_df[[\"horsepower\"]])\n",
    "\n",
    "# Convert back to DataFrames\n",
    "poly_feature_names = poly.get_feature_names_out([\"horsepower\"])\n",
    "\n",
    "horsepower_train_poly = pd.DataFrame(\n",
    "    horsepower_train_poly,\n",
    "    columns=poly_feature_names,\n",
    "    index=train_df.index\n",
    ")\n",
    "\n",
    "horsepower_test_poly = pd.DataFrame(\n",
    "    horsepower_test_poly,\n",
    "    columns=poly_feature_names,\n",
    "    index=test_df.index\n",
    ")\n",
    "\n",
    "# Add squared term back to original data\n",
    "train_df[\"horsepower_squared\"] = horsepower_train_poly[\"horsepower^2\"]\n",
    "test_df[\"horsepower_squared\"]  = horsepower_test_poly[\"horsepower^2\"]\n",
    "\n",
    "# Show result\n",
    "print(\"Training columns:\", train_df.columns.tolist())\n",
    "print(\"Test columns:\", test_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d181c81f-25ee-4e2d-93bf-825f16cad6e3",
   "metadata": {},
   "source": [
    "# Let's start over and build a full model using Kfold approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7eccbf-59b7-4465-8561-54d4c7cc7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"data/auto-mpg.csv\")\n",
    "\n",
    "# Simple cleanup: drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[\"mpg\"])\n",
    "y = df[\"mpg\"]\n",
    "\n",
    "# 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "r2_scores = []\n",
    "rmse_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Train linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # Metrics\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "    rmse_scores.append(rmse)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "# Average metrics\n",
    "print(\"Average R-squared:\", np.mean(r2_scores))\n",
    "print(\"Average RMSE:\", np.mean(rmse_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3da3a29-4bc6-4810-9d38-ec2380c201e4",
   "metadata": {},
   "source": [
    "# And again, let's start fresh adding some automated model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f45fbf-b786-4ab5-9056-c881ce98e276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# -----------------------\n",
    "# Load and prepare data\n",
    "# -----------------------\n",
    "df = pd.read_csv(\"data/auto-mpg.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "X = df.drop(columns=[\"mpg\"])\n",
    "y = df[\"mpg\"]\n",
    "\n",
    "# Split into training (70%) and test (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=seed\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# Pick best polynomial degree using 5-fold CV on TRAINING only\n",
    "# -----------------------\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def cv_scores_for_degree(degree):\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X_train)\n",
    "\n",
    "    r2_list = []\n",
    "    rmse_list = []\n",
    "\n",
    "    # We'll wrap X_poly in a DataFrame so .iloc works easily\n",
    "    X_poly = pd.DataFrame(X_poly)\n",
    "\n",
    "    for tr_idx, val_idx in kf.split(X_poly):\n",
    "        X_tr = X_poly.iloc[tr_idx]\n",
    "        X_val = X_poly.iloc[val_idx]\n",
    "        y_tr = y_train.iloc[tr_idx]\n",
    "        y_val = y_train.iloc[val_idx]\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        preds = model.predict(X_val)\n",
    "\n",
    "        r2_list.append(r2_score(y_val, preds))\n",
    "        rmse_list.append(np.sqrt(mean_squared_error(y_val, preds)))\n",
    "\n",
    "    return np.mean(r2_list), np.mean(rmse_list)\n",
    "\n",
    "results = {}\n",
    "for degree in [1, 2]:\n",
    "    avg_r2, avg_rmse = cv_scores_for_degree(degree)\n",
    "    results[degree] = (avg_r2, avg_rmse)\n",
    "    print(f\"Degree {degree} CV -> Avg R²: {avg_r2:.4f}, Avg RMSE: {avg_rmse:.4f}\")\n",
    "\n",
    "# Choose best degree (highest R²; if tie, lowest RMSE)\n",
    "best_degree = max(results.keys(), key=lambda d: (results[d][0], -results[d][1]))\n",
    "print(\"\\nBest polynomial degree:\", best_degree)\n",
    "\n",
    "# -----------------------\n",
    "# Train FINAL model on full training set using best degree\n",
    "# -----------------------\n",
    "poly = PolynomialFeatures(degree=best_degree, include_bias=False)\n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)   # IMPORTANT: transform only\n",
    "\n",
    "final_model = LinearRegression()\n",
    "final_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# -----------------------\n",
    "# Evaluate on test set\n",
    "# -----------------------\n",
    "test_preds = final_model.predict(X_test_poly)\n",
    "\n",
    "test_r2 = r2_score(y_test, test_preds)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "\n",
    "print(\"\\nTest set results:\")\n",
    "print(\"  R-squared:\", test_r2)\n",
    "print(\"  RMSE     :\", test_rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce66d6d-42a4-4353-bc5c-cbee3c49defd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
